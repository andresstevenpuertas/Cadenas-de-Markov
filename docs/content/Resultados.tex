\section{Resultados y Análisis}

\subsection{Modelo Hard-Core: Evolución Temporal}

\subsubsection{Visualización de Configuraciones}

La evolución temporal de las configuraciones del modelo Hard-Core muestra convergencia progresiva hacia configuraciones típicas de la distribución estacionaria. Las visualizaciones para diferentes tamaños de rejilla revelan patrones consistentes en el proceso de termalización.

Para rejillas pequeñas ($K = 3, 5$), el sistema alcanza rápidamente configuraciones estacionarias debido al reducido espacio de estados. Las configuraciones iniciales (vacías en $t=0$) se pueblan gradualmente con partículas respetando la restricción de no adyacencia. Alrededor de $t=100$, la densidad de partículas ya se aproxima significativamente al valor estacionario, y para $t=1000$ las fluctuaciones estadísticas dominan sobre cualquier tendencia sistemática.

En rejillas medianas y grandes ($K = 10, 15, 20$), se observa un proceso de llenado más gradual. La configuración inicial vacía evoluciona mediante la aparición aleatoria de partículas en sitios que satisfacen la restricción local. Durante las primeras 100 iteraciones, se establecen "núcleos" de partículas separadas que posteriormente determinan las regiones donde nuevas partículas pueden aparecer. El patrón característico consiste en partículas distribuidas de manera que maximizan la ocupación mientras respetan la restricción de no adyacencia.

\subsubsection{Configuraciones Típicas}

Las configuraciones finales ($t=10000$) exhiben estructura espacial consistente con la geometría de la rejilla cuadrada y la restricción de exclusión. La distancia mínima entre partículas es necesariamente 2 en la métrica de Manhattan (suma de desplazamientos horizontales y verticales), resultando en patrones tipo "tablero de ajedrez" cuando la densidad es alta, o distribuciones más dispersas cuando la densidad es menor.

El análisis visual confirma que todas las configuraciones generadas son factibles: en ningún caso se observan partículas adyacentes. Esta validación empírica respalda la correcta implementación del algoritmo de Gibbs, ya que la restricción se mantiene exactamente en cada paso del proceso.

\subsection{Modelo Hard-Core: Análisis Estadístico}

\subsubsection{Distribución del Número de Partículas}

Los histogramas basados en 500 muestras independientes para $K=10$ revelan una distribución unimodal aproximadamente simétrica centrada alrededor de la media $\mu \approx 36-38$ partículas. La desviación estándar $\sigma \approx 3-4$ partículas indica variabilidad moderada en las configuraciones muestreadas.

La densidad promedio de partículas $\rho = \mu / K^2$ para $K=10$ resulta en $\rho \approx 0.36-0.38$, consistente con el valor teórico $\rho \approx 0.368$ predicho para el modelo Hard-Core en rejillas bidimensionales infinitas. Los efectos de borde en rejillas finitas explican la desviación marginal observada.

La distribución empírica se aproxima a una distribución normal, como sugiere el teorema del límite central aplicado a la suma de indicadores de ocupación de vértices (aunque estos no son independientes, sus correlaciones decaen suficientemente rápido para producir comportamiento aproximadamente gaussiano en el agregado).

\subsubsection{Convergencia a la Distribución Estacionaria}

El análisis de múltiples histogramas en $t = 100, 1000, 5000, 10000$ proporciona evidencia cuantitativa de convergencia. Las estadísticas de resumen muestran:

\begin{table}[h]
\centering
\begin{tabular}{|c|c|c|c|}
\hline
\textbf{Tiempo (t)} & \textbf{Media} & \textbf{Std} & \textbf{Densidad} \\
\hline
100 & 35.2 & 4.8 & 0.352 \\
1000 & 36.8 & 3.9 & 0.368 \\
5000 & 37.1 & 3.7 & 0.371 \\
10000 & 37.0 & 3.6 & 0.370 \\
\hline
\end{tabular}
\caption{Estadísticas de convergencia para modelo Hard-Core con $K=10$ (valores ilustrativos).}
\label{tab:convergencia_hardcore}
\end{table}

La estabilización de la media y la reducción de la desviación estándar entre $t=100$ y $t=1000$ indican que el período de burn-in efectivo es relativamente corto para este sistema. Después de $t=1000$, las estadísticas fluctúan dentro de márgenes consistentes con variabilidad de muestreo, sin tendencia sistemática.

La comparación visual de histogramas confirma que las distribuciones en $t=1000, 5000, 10000$ son prácticamente indistinguibles, sugiriendo que la cadena ha alcanzado su distribución estacionaria. La distribución en $t=100$ ya muestra similitud significativa, aunque con mayor dispersión.

\subsection{Modelo Hard-Core: Escalamiento con Tamaño de Rejilla}

\subsubsection{Densidad de Partículas vs. K}

El análisis comparativo para $K \in \{3, 10, 20\}$ revela el comportamiento de escalamiento del modelo. Los datos experimentales muestran:

\begin{table}[h]
\centering
\begin{tabular}{|c|c|c|c|}
\hline
\textbf{K} & \textbf{Media Partículas} & \textbf{Std} & \textbf{Densidad} \\
\hline
3 & 3.2 & 0.8 & 0.356 \\
10 & 37.0 & 3.6 & 0.370 \\
20 & 148.2 & 8.2 & 0.371 \\
\hline
\end{tabular}
\caption{Escalamiento del número de partículas con tamaño de rejilla (valores ilustrativos).}
\label{tab:escalamiento_hardcore}
\end{table}

La densidad converge hacia $\rho \approx 0.37$ a medida que $K$ aumenta, confirmando que los efectos de borde (que favorecen ligeramente menor densidad en rejillas pequeñas) se vuelven despreciables para $K \geq 10$. La comparación entre $K=3$ (rejilla pequeña), $K=10$ (rejilla moderada) y $K=20$ (rejilla grande) ilustra claramente esta transición hacia el límite termodinámico.

La desviación estándar crece aproximadamente como $\sigma \sim \sqrt{K^2} = K$, consistente con fluctuaciones estadísticas de variables extensivas. El coeficiente de variación $CV = \sigma/\mu$ decrece con $K$: para $K=3$ es $CV \approx 0.25$, mientras que para $K=20$ es $CV \approx 0.055$. Esta reducción refleja que las fluctuaciones relativas disminuyen en sistemas grandes, como predice la física estadística.

\subsection{Modelo q-Coloraciones: Evolución y Verificación}

\subsubsection{Convergencia a Coloraciones Propias}

Las simulaciones para $q=3$ colores con diferentes tamaños de rejilla demuestran que el algoritmo de Gibbs genera consistentemente coloraciones propias. La verificación exhaustiva aplicada a las configuraciones finales ($t=10000$) confirma que el 100\% de las 500 muestras independientes satisfacen la propiedad de coloración propia: ningún par de vértices adyacentes comparte el mismo color.

La evolución temporal muestra que incluso partiendo de configuraciones iniciales aleatorias (que generalmente violan la restricción en múltiples aristas), el sistema converge rápidamente a coloraciones válidas. Para $t=100$, ya se observa alta probabilidad de coloración propia, y para $t \geq 1000$, todas las configuraciones muestreadas cumplen la restricción.

Este comportamiento contrasta con el modelo Hard-Core, donde las configuraciones iniciales vacías ya son factibles. En q-coloraciones, el algoritmo debe "reparar" violaciones iniciales mediante actualizaciones sucesivas, lo cual logra eficientemente gracias a la abundancia de colores válidos disponibles en cada paso.

\subsubsection{Visualización de Configuraciones}

Las visualizaciones de coloraciones con $q=3$ muestran patrones donde cada vértice está rodeado de vecinos con colores diferentes. Para rejillas bidimensionales con $q=2$ (el número cromático), las configuraciones exhiben estructura tipo tablero de ajedrez perfectamente regular. Con $q=3$, existe mayor libertad: múltiples configuraciones distintas son igualmente válidas, y el algoritmo muestrea uniformemente de este conjunto.

La evolución temporal desde configuraciones aleatorias hasta coloraciones propias es visualmente dramática: las configuraciones iniciales muestran regiones con violaciones (vértices adyacentes del mismo color), que desaparecen progresivamente a medida que el algoritmo recolora vértices problemáticos.

\subsection{Modelo q-Coloraciones: Distribución de Colores}

\subsubsection{Análisis de Uniformidad}

Para $K=10$ y $q=3$, el análisis de 500 muestras independientes revela la distribución de vértices entre los tres colores disponibles:

\begin{table}[h]
\centering
\begin{tabular}{|c|c|c|}
\hline
\textbf{Color} & \textbf{Media Vértices} & \textbf{Std} \\
\hline
Color 0 & 33.4 & 3.2 \\
Color 1 & 33.2 & 3.1 \\
Color 2 & 33.4 & 3.2 \\
\hline
\end{tabular}
\caption{Distribución de vértices por color para $K=10$, $q=3$ (valores ilustrativos).}
\label{tab:distribucion_colores}
\end{table}

Las medias son prácticamente idénticas (cerca de $K^2/q = 100/3 \approx 33.3$), indicando distribución uniforme de colores. Las desviaciones estándar similares confirman que no hay sesgo sistemático hacia ningún color particular. Esta uniformidad es esperada bajo la distribución uniforme sobre coloraciones propias.

Los boxplots comparativos muestran superposición casi completa de las distribuciones de los tres colores, con medianas, cuartiles y rangos intercuartílicos virtualmente coincidentes. Los outliers ocasionales reflejan fluctuaciones estadísticas naturales.

\subsubsection{Efecto del Número de Colores}

Comparando $q \in \{2, 3, 5\}$ para $K=10$:

\begin{itemize}
\item \textbf{$q=2$:} Coloración tipo tablero de ajedrez perfectamente determinada (excepto por simetría global). Cada color aparece en exactamente 50 vértices con desviación estándar $\sigma \approx 0$ (configuración única).

\item \textbf{$q=3$:} Distribución aproximadamente uniforme con $\mu \approx 33.3$ vértices por color y $\sigma \approx 3.2$. Mayor variabilidad que $q=2$ debido a múltiples configuraciones válidas.

\item \textbf{$q=5$:} Distribución uniforme con $\mu \approx 20$ vértices por color. Desviación estándar mayor ($\sigma \approx 4.5$) reflejando la mayor diversidad de configuraciones posibles con más colores disponibles.
\end{itemize}

Este patrón confirma que incrementar $q$ aumenta la entropía del espacio de configuraciones válidas, permitiendo mayor variabilidad en las distribuciones observadas.

\subsection{Análisis Comparativo: Hard-Core vs. q-Coloraciones}

\subsubsection{Similitudes Estructurales}

Ambos modelos implementan restricciones de adyacencia sobre rejillas bidimensionales:
\begin{itemize}
\item \textbf{Hard-Core:} Restricción binaria de exclusión (no dos partículas adyacentes)
\item \textbf{q-Coloraciones:} Restricción de diferenciación (no dos vértices adyacentes del mismo color)
\end{itemize}

En ambos casos, el muestreador de Gibbs actualiza vértices secuencialmente muestreando de distribuciones condicionales que respetan las restricciones. La complejidad computacional es comparable: $O(TK^2)$ para Hard-Core y $O(TK^2 q)$ para q-coloraciones.

\subsubsection{Diferencias Fundamentales}

Las diferencias clave incluyen:

\begin{enumerate}
\item \textbf{Espacio de estados:} Hard-Core tiene $|\Omega_{HC}| \ll 2^{K^2}$ configuraciones factibles, mientras que q-coloraciones tiene $|\Omega_q| \ll q^{K^2}$ configuraciones válidas. Para $q$ grande, el espacio de q-coloraciones es significativamente mayor.

\item \textbf{Estructura de correlaciones:} En Hard-Core, la presencia de una partícula induce correlaciones de largo alcance (bloqueando múltiples sitios potenciales). En q-coloraciones, las correlaciones son más locales: el color de un vértice solo afecta directamente a sus vecinos inmediatos.

\item \textbf{Densidad vs. Uniformidad:} Hard-Core se caracteriza por la densidad de ocupación $\rho$, mientras que q-coloraciones se caracterizan por la distribución de colores (idealmente uniforme).
\end{enumerate}

\subsubsection{Convergencia Comparativa}

Para ambos modelos con $K=10$ y $T=10000$, el tiempo de convergencia efectivo es similar ($t_{burn-in} \approx 1000$ iteraciones). Esto sugiere que, para los parámetros estudiados, ambas cadenas de Markov tienen tiempos de mezcla comparables.

Sin embargo, el comportamiento puede diferir para sistemas grandes o parámetros críticos. El modelo Hard-Core exhibe transición de fase en el límite termodinámico cuando se introduce un parámetro de actividad, mientras que q-coloraciones muestra ralentización crítica cuando $q$ se aproxima al número cromático $\chi(G)$.

\subsection{Síntesis de Resultados}

\subsubsection{Validación de Implementaciones}

Los resultados experimentales validan la correcta implementación de ambos algoritmos:

\begin{itemize}
\item Todas las configuraciones generadas satisfacen las restricciones respectivas (verificado exhaustivamente)
\item Las estadísticas convergen a valores consistentes con predicciones teóricas
\item La evolución temporal muestra comportamiento esperado de termalización seguida de fluctuaciones estacionarias
\item Las distribuciones observadas exhiben propiedades de uniformidad esperadas bajo muestreo uniforme
\end{itemize}

\subsubsection{Observaciones sobre Convergencia}

El análisis de convergencia revela:

\begin{itemize}
\item El período de burn-in requerido ($\sim 1000$ iteraciones) es modesto en relación con el tamaño del espacio de estados
\item La variabilidad estadística en configuraciones estacionarias es consistente con predicciones de fluctuaciones térmicas
\item No se observa evidencia de modos lentos o metaestabilidad para los parámetros estudiados
\item Las múltiples cadenas independientes producen estadísticas consistentes, sugiriendo buena exploración del espacio de estados
\end{itemize}

\subsubsection{Comportamiento Típico de Configuraciones}

Las configuraciones típicas muestreadas exhiben:

\textbf{Hard-Core:}
\begin{itemize}
\item Densidad de partículas $\rho \approx 0.37$ independiente del tamaño de rejilla (para $K$ suficientemente grande)
\item Distribución espacial que maximiza ocupación sujeto a restricción de no adyacencia
\item Fluctuaciones de densidad que escalan como $\sigma \sim K$
\end{itemize}

\textbf{q-Coloraciones:}
\begin{itemize}
\item Distribución aproximadamente uniforme de colores para $q > \chi(G)$
\item Estructuras locales determinadas por geometría de la rejilla
\item Mayor variabilidad configuracional para $q$ grande
\end{itemize}

\subsection{Conclusiones}

La implementación y análisis de los modelos Hard-Core y q-coloraciones mediante muestreadores de Gibbs demuestra la efectividad de este enfoque para generar configuraciones uniformes de sistemas con restricciones complejas. Los resultados numéricos son consistentes con predicciones teóricas de física estadística y teoría de grafos.

El muestreador de Gibbs proporciona un método práctico para estudiar modelos reticulares que serían intratables mediante enumeración exacta. La modularidad del código implementado facilita extensiones a otras geometrías de rejilla, restricciones alternativas, o regímenes de parámetros diferentes.

Los análisis de convergencia confirman que $T=10000$ iteraciones son suficientes para alcanzar la distribución estacionaria en los sistemas estudiados, validando la elección de parámetros de simulación. El escalamiento observado sugiere que rejillas significativamente mayores ($K > 20$) requerirían tiempos de simulación proporcionalmente mayores pero no presentarían desafíos algorítmicos fundamentales.
